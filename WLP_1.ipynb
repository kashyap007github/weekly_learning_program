{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b08146b6-de53-457a-a0eb-dfad32211cb0",
   "metadata": {},
   "source": [
    "# Weekly Learning Program (25/May/24 - 31/May/24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e19c9f1-815d-4eda-9f8c-518aa9989976",
   "metadata": {},
   "source": [
    "I am starting this weekly Jupyter notebook series to help us improve our technical skills and become interview-ready for any internal job postings. Our ultimate goal is to prepare an end-to-end NLP model with minimal help from ChatGPT. The technical skills covered will include SQL, Python (pandas, numpy, nltk, and other data-related libraries), Excel,and Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e640d9d3-72e6-4fb6-9d82-eae532a8c74c",
   "metadata": {},
   "source": [
    "* I will share a notebook every week that will have problem statements related to SQL, Python, and ML.\n",
    "* Please download that notebook and complete the solution.\n",
    "* Once done, Save that notebook to your GitHub project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d340975-368b-40de-9684-12b9f495a442",
   "metadata": {},
   "source": [
    "## How to save your projects on github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f5f6d-feb6-4e7c-9e82-02c6211430f8",
   "metadata": {},
   "source": [
    "#### create account on hithub\n",
    "\n",
    "* Log in to your GitHub account.\n",
    "#### Create a New Repository\n",
    "\n",
    "* Click on the \"+\" icon in the upper right corner and select \"New repository\".\n",
    "* Enter a repository name, for example, weekly-notebooks.\n",
    "* Optionally, add a description.\n",
    "* Choose the visibility (public or private).\n",
    "* Optionally, initialize the repository with a README file.\n",
    "* Click on \"Create repository\".\n",
    "* Uploading Your First Jupyter Notebook\n",
    "* Open Your Repository\n",
    "\n",
    "#### Navigate to your newly created repository.\n",
    "* Upload Files\n",
    "\n",
    "* Click on the \"Add file\" button and select \"Upload files\".\n",
    "* Drag and drop your Jupyter notebook file (with a .ipynb extension) into the upload area, or click on \"choose your files\" to select the file from your computer.\n",
    "* Add a commit message, for example, \"Add first weekly notebook\".\n",
    "* Click on \"Commit changes\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b6e71-ec61-4dab-91f8-4733e6d11bce",
   "metadata": {},
   "source": [
    "### Some Key Points to Remember\n",
    "\n",
    "* Always include extensive comments in your solutions.\n",
    "* It would be beneficial to explain the logic you used to solve each problem.\n",
    "* Once finished, compare your solution with the best available solutions on the internet to enhance your problem-solving skills.\n",
    "* If you get stuck, ask ChatGPT for hints rather than the complete solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06c8f1f-f958-4284-aab3-50fe498763aa",
   "metadata": {},
   "source": [
    "## What Will the WLP (Weekly Learning Program) Notebook Include?\n",
    "\n",
    "* 3-4 SQL questions\n",
    "* 2-3 Python questions related to data manipulation (using numpy and pandas)\n",
    "* Snippets and explanations related to NLP (to solve, read, or understand)\n",
    "* Mathematical concepts used in ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b318e9b1-c6b4-49a0-919c-c3d72e50a808",
   "metadata": {},
   "source": [
    "### Where to Solve the SQL Questions?\n",
    "\n",
    "* I will provide the dataset along with the questions.\n",
    "* You can use the following website to practice the SQL questions: [Programiz SQL Compiler](https://www.programiz.com/sql/online-compiler/)\n",
    "* Please paste your solutions into the Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185ee78d-3663-4b25-acd1-4d7a7664105b",
   "metadata": {},
   "source": [
    "# SQL QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2cccf2-a68a-4b96-9261-780dda2c2f54",
   "metadata": {},
   "source": [
    "### 1. Given an Employee table with columns Id and Salary, write a query to find the second highest salary. If there is no second highest salary, the query should return NULL.\n",
    "\n",
    "* Dataset 1: Contains Second Highest Salary\n",
    "\n",
    "```sql\n",
    "CREATE TABLE Employees (\n",
    "    Id INT PRIMARY KEY,\n",
    "    Salary INT\n",
    ");\n",
    "\n",
    "INSERT INTO Employees (Id, Salary) VALUES\n",
    "(1, 150),\n",
    "(2, 250),\n",
    "(3, 350),\n",
    "(4, 450);\n",
    "```\n",
    "\n",
    "* Dataset 2: No Second Highest Salary\n",
    "\n",
    "```sql\n",
    "CREATE TABLE Employees (\n",
    "    Id INT PRIMARY KEY,\n",
    "    Salary INT\n",
    ");\n",
    "\n",
    "INSERT INTO Employees (Id, Salary) VALUES\n",
    "(1, 500),\n",
    "(2, 500),\n",
    "(3, 500);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6281d55b-7c34-40a8-a347-e8f0b9fe776b",
   "metadata": {},
   "source": [
    "#### Solution below\n",
    "* ##using rank function to find the rank of salary\n",
    "* ##using case statement to find if rank 2 is present\n",
    "```\n",
    "with second as\n",
    " (\n",
    "   select *,rank()over(order by salary) rnk\n",
    "   from employees\n",
    " )\n",
    " select case when rnk = 2 then salary else null end as second_highest_salary\n",
    " from second\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b853b4f-f017-4189-b0c9-8d8a37479769",
   "metadata": {},
   "source": [
    "### 2. Write a SQL query to get the nth highest salary from the Employees table. For example, given the Employee table below, the nth highest salary where n = 2 is 250. If there is no nth highest salary, the query should return NULL. PLease use parameter to perform this task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f9caca-e6ec-4e02-a685-49e66ff9d9c3",
   "metadata": {},
   "source": [
    "* Dataset 1:\n",
    "  \n",
    "``` CREATE TABLE Employees (\n",
    "    Id INT PRIMARY KEY,\n",
    "    Salary INT\n",
    ");\n",
    "\n",
    "INSERT INTO Employees (Id, Salary) VALUES\n",
    "(1, 150),\n",
    "(2, 250),\n",
    "(3, 350),\n",
    "(4, 450);\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Dataset 2:\n",
    "\n",
    "```CREATE TABLE Employees (\n",
    "    Id INT PRIMARY KEY,\n",
    "    Salary INT\n",
    ");\n",
    "\n",
    "INSERT INTO Employees (Id, Salary) VALUES\n",
    "(1, 400),\n",
    "(2, 400),\n",
    "(3, 400);\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b90073-2cf7-4e60-be45-eefb7bac6006",
   "metadata": {},
   "source": [
    "#### Solution below\n",
    "```\n",
    "DECLARE @rnk int = 2;\n",
    "with second as\n",
    " (\n",
    "   select *,rank()over(order by salary) rnk\n",
    "   from employees\n",
    " )\n",
    " select case when rnk = @rnk then salary else null end as second_highest_salary\n",
    " from second\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ad022f-8056-4321-83fa-ca5f4ae66d99",
   "metadata": {},
   "source": [
    "### 3. Write a SQL query to find all numbers that appear at least three times consecutively in the Logs table. For example, given the Logs table below, the number 3 appears consecutively at least three times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3554a5-a2e9-4686-818d-9d86e69ed508",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "CREATE TABLE Logs (\n",
    "    Id INT PRIMARY KEY,\n",
    "    Num INT\n",
    ");\n",
    "\n",
    "INSERT INTO Logs (Id, Num) VALUES\n",
    "(1, 2),\n",
    "(2, 2),\n",
    "(3, 2),\n",
    "(4, 3),\n",
    "(5, 3),\n",
    "(6, 3),\n",
    "(7, 1)\n",
    "(8, 2);\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640de131-4e1a-4c24-b112-318db510c168",
   "metadata": {},
   "source": [
    "#### Solution below\n",
    "\n",
    "```\n",
    "with\n",
    "rnk\n",
    "as\n",
    "\t(\n",
    "      select id,num,rank()over(partition by num order by id) rnk,\n",
    "             id-rank()over(partition by num order by id) diff\n",
    "      from logs\n",
    "    )\n",
    "select num,diff,count(diff) consecutive\n",
    "from rnk\n",
    "group by num,diff\n",
    "having consecutive >=3\n",
    "order by id\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e011970-05c8-490f-abf2-c95512a05528",
   "metadata": {},
   "source": [
    "# PANDAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48482e8-f27a-4fdd-a642-9dbf08e2f30c",
   "metadata": {},
   "source": [
    "### 1: Calculate the Mean Salary by Department and Filter Departments with Average Salary Above a Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1fbc5e1-58af-4c99-8458-f012c41b2cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Sample data\n",
    "data = {\n",
    "    'EmployeeId': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'Department': ['HR', 'IT', 'HR', 'IT', 'HR', 'Sales', 'IT', 'Sales', 'HR', 'Sales'],\n",
    "    'Salary': [4000, 5000, 4200, 5500, 4500, 6000, 4800, 6200, 4700, 6300]\n",
    "}\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcc122d0-8c2f-4392-895a-0a5f17ac3e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department\n",
      "HR       4350.000000\n",
      "IT       5100.000000\n",
      "Sales    6166.666667\n",
      "Name: Salary, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Department\n",
       "IT       5100.000000\n",
       "Sales    6166.666667\n",
       "Name: Salary, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SOLUTION HERE\n",
    "grouped_dept_mean = df.groupby('Department')['Salary'].mean()\n",
    "print(grouped_dept_mean)\n",
    "threshold = 5000\n",
    "filtered_grouped_dept_mean = grouped_dept_mean[grouped_dept_mean>threshold]\n",
    "filtered_grouped_dept_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff3bce-9456-4f1e-9a03-a28407685261",
   "metadata": {},
   "source": [
    "### 2. Write a pandas code snippet to filter the rows where the Age is greater than 30 and the Salary is less than 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a096e844-5bf1-47e9-82cb-53e31f420307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'EmployeeId': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'Age': [25, 30, 45, 28, 32, 41, 34, 29, 30, 31],\n",
    "    'Department': ['HR', 'IT', 'HR', 'IT', 'HR', 'Sales', 'IT', 'Sales', 'HR', 'Sales'],\n",
    "    'Salary': [4000, 5000, 4200, 5500, 4500, 6000, 4800, 6200, 4700, 6300]\n",
    "}\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccce308f-1a9e-4aea-b4cc-7b9dbdb2e991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeId</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>HR</td>\n",
       "      <td>4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>HR</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>IT</td>\n",
       "      <td>4800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeId  Age Department  Salary\n",
       "2           3   45         HR    4200\n",
       "4           5   32         HR    4500\n",
       "6           7   34         IT    4800"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Solution here\n",
    "df[(df['Age']>30) & (df['Salary']<5000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdbb0ed-29ff-42f9-ad20-a9971bca9d4e",
   "metadata": {},
   "source": [
    "### 3. Write a pandas code snippet to add a new column SalaryLevel to the DataFrame df. The SalaryLevel column should contain 'High' if the Salary is greater than 5000, 'Medium' if the Salary is between 4500 and 5000, and 'Low' if the Salary is less than 4500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "425168cc-4402-4750-8b51-0e5ac79d8559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'EmployeeId': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'Department': ['HR', 'IT', 'HR', 'IT', 'HR', 'Sales', 'IT', 'Sales', 'HR', 'Sales'],\n",
    "    'Salary': [4000, 5000, 4200, 5500, 4500, 6000, 4800, 6200, 4700, 6300]\n",
    "}\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb01700c-88a0-4ea7-9bb8-b28cfe9706e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmployeeId Department  Salary SalaryLevel\n",
      "0           1         HR    4000         Low\n",
      "1           2         IT    5000      Medium\n",
      "2           3         HR    4200         Low\n",
      "3           4         IT    5500        High\n",
      "4           5         HR    4500         Low\n",
      "5           6      Sales    6000        High\n",
      "6           7         IT    4800      Medium\n",
      "7           8      Sales    6200        High\n",
      "8           9         HR    4700      Medium\n",
      "9          10      Sales    6300        High\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "df['SalaryLevel'] = df['Salary'].apply(lambda x : 'High' if x > 5000 else ('Medium' if x>4500 else 'Low'))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52376e94-616f-4c1a-a4c6-835c59ab78ff",
   "metadata": {},
   "source": [
    "# NLP & NLP MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cc0836-d63b-4267-a44f-ca096ecfec31",
   "metadata": {},
   "source": [
    "### What is NLP?\n",
    "\n",
    "**Natural Language Processing (NLP)** is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language. It involves the development of algorithms and models that enable computers to understand, interpret, and generate human language.\n",
    "\n",
    "### Different Models in NLP\n",
    "\n",
    "#### Basic Models\n",
    "\n",
    "1. **Bag of Words (BoW)**\n",
    "   - Represents text data as a collection of words, disregarding grammar and word order.\n",
    "   - Uses word frequencies or occurrences.\n",
    "\n",
    "2. **Term Frequency-Inverse Document Frequency (TF-IDF)**\n",
    "   - Enhances the BoW model by considering the importance of words.\n",
    "   - Weights words based on their frequency in a document and their rarity across documents.\n",
    "\n",
    "3. **n-Grams**\n",
    "   - Considers sequences of n words to capture context.\n",
    "   - Common examples include bigrams (2 words) and trigrams (3 words).\n",
    "\n",
    "4. **Latent Semantic Analysis (LSA)**\n",
    "   - Reduces dimensionality using Singular Value Decomposition (SVD).\n",
    "   - Captures hidden semantic structures in text data.\n",
    "\n",
    "#### Intermediate Models\n",
    "\n",
    "5. **Word Embeddings**\n",
    "   - **Word2Vec**: Uses neural networks to learn word associations.\n",
    "   - **GloVe**: Combines global word co-occurrence statistics with local context-based learning.\n",
    "   - **FastText**: Extends Word2Vec by considering subword information.\n",
    "\n",
    "6. **Topic Modeling**\n",
    "   - **Latent Dirichlet Allocation (LDA)**: Probabilistic model that discovers topics within a collection of documents.\n",
    "   - **Non-Negative Matrix Factorization (NMF)**: Matrix decomposition technique for identifying latent topics.\n",
    "\n",
    "#### Advanced Models\n",
    "\n",
    "7. **Recurrent Neural Networks (RNNs)**\n",
    "   - Captures sequential dependencies in text.\n",
    "   - **Long Short-Term Memory (LSTM)**: Addresses the vanishing gradient problem in RNNs.\n",
    "   - **Gated Recurrent Units (GRUs)**: Simplified version of LSTM with fewer parameters.\n",
    "\n",
    "8. **Convolutional Neural Networks (CNNs)**\n",
    "   - Originally designed for image processing but effective for text classification tasks.\n",
    "\n",
    "9. **Attention Mechanisms**\n",
    "   - Enhances the ability of models to focus on relevant parts of the input sequence.\n",
    "   - **Bahdanau Attention**: An early form of attention in neural machine translation.\n",
    "\n",
    "#### Latest Models\n",
    "\n",
    "10. **Transformers**\n",
    "    - Revolutionized NLP by introducing self-attention mechanisms.\n",
    "    - Examples include:\n",
    "      - **BERT (Bidirectional Encoder Representations from Transformers)**\n",
    "      - **GPT (Generative Pre-trained Transformer)**\n",
    "      - **RoBERTa (Robustly optimized BERT approach)**\n",
    "      - **XLNet**\n",
    "      - **T5 (Text-To-Text Transfer Transformer)**\n",
    "      - **ALBERT (A Lite BERT)**\n",
    "      - **BART (Bidirectional and Auto-Regressive Transformers)**\n",
    "      - **DistilBERT**: A smaller, faster, and lighter version of BERT.\n",
    "      - **ERNIE (Enhanced Representation through kNowledge Integration)**\n",
    "\n",
    "11. **Multimodal Models**\n",
    "    - Combines text with other data types like images.\n",
    "    - Examples include:\n",
    "      - **CLIP (Contrastive Languageâ€“Image Pre-training)**\n",
    "      - **DALL-E**: Generates images from textual descriptions.\n",
    "\n",
    "12. **Large Language Models (LLMs)**\n",
    "    - Extensive pre-training on diverse datasets.\n",
    "    - Examples include:\n",
    "      - **GPT-3 and GPT-4**: Very large models with billions of parameters.\n",
    "      - **PaLM (Pathways Language Model)**\n",
    "      - **ChatGPT**: Fine-tuned versions of GPT models for conversational tasks.\n",
    "      - **LLaMA (Large Language Model Meta AI)**\n",
    "\n",
    "These models represent the evolution of NLP from simple word-based representations to complex, deep learning architectures capable of understanding and generating human language with high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bc4c13-18ac-4dc7-999d-d132f12e9723",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
