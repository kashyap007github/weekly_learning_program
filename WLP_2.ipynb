{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f91041e1-2863-4deb-85aa-273a2d1b591e",
   "metadata": {},
   "source": [
    "# Weekly Learning Program (01/June/24 - 07/June/24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9882aa2-b7b1-41ad-afac-5708bf2b94ce",
   "metadata": {},
   "source": [
    "### Where to Solve the SQL Questions?\n",
    "\n",
    "* I will provide the dataset along with the questions.\n",
    "* You can use the following website to practice the SQL questions: [Programiz SQL Compiler](https://www.programiz.com/sql/online-compiler/)\n",
    "* Please paste your solutions into the Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a5a6ec-943a-477c-9415-d8a060871f5f",
   "metadata": {},
   "source": [
    "### Instruction for this\n",
    "* Read the articles below(Dimension and BOW)\n",
    "* Answer the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9950ed-6f7c-4fc3-8f39-e7019f71d463",
   "metadata": {},
   "source": [
    "## SQL QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a923200-8328-461a-8543-cf195721cd5d",
   "metadata": {},
   "source": [
    "#### 1. Given an Employee table containing the Id, Name, Salary, and ManagerId columns, write a SQL query to find the names of employees who earn more than their managers.\n",
    "\n",
    "``` sql\n",
    "CREATE TABLE Employee (\n",
    "    Id INT PRIMARY KEY,\n",
    "    Name NVARCHAR(50),\n",
    "    Salary INT,\n",
    "    ManagerId INT\n",
    ");\n",
    "\n",
    "INSERT INTO Employee (Id, Name, Salary, ManagerId) VALUES\n",
    "(1, 'Alice', 50000, 3),\n",
    "(2, 'Bob', 60000, 3),\n",
    "(3, 'Charlie', 55000, NULL),\n",
    "(4, 'David', 70000, 5),\n",
    "(5, 'Eve', 65000, NULL),\n",
    "(6, 'Frank', 72000, 4);\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b80117-a161-4747-9fb5-992dca5b1fe1",
   "metadata": {},
   "source": [
    "* solution here\n",
    "``` sql\n",
    "with\n",
    "full_table\n",
    "as\n",
    "\t(\n",
    "  select e.Name as emp,m.Name as manager,e.Salary emp_sal , m.Salary as manager_sal\n",
    "  from employee e\n",
    "  left join employee m\n",
    "  on e.ManagerId = m.Id\n",
    "      )\n",
    "SELECT emp\n",
    "from full_table\n",
    "where manager_sal< emp_sal\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6f89e-69b7-4d92-b215-2f206abb1230",
   "metadata": {},
   "source": [
    "\n",
    "#### 2. Given a `Weather` table with columns `Id` (integer), `RecordDate` (date), and `Temperature` (integer), write a SQL query to retrieve the `Id` of all dates where the temperature is higher than the temperature of the previous date.\n",
    "\n",
    "\n",
    "\n",
    "```sql\n",
    "CREATE TABLE Weather (\n",
    "    Id INT PRIMARY KEY,\n",
    "    RecordDate DATE,\n",
    "    Temperature INT\n",
    ");\n",
    "\n",
    "INSERT INTO Weather (Id, RecordDate, Temperature) VALUES\n",
    "(1, '2024-06-01', 23),\n",
    "(2, '2024-06-02', 27),\n",
    "(3, '2024-06-03', 24),\n",
    "(4, '2024-06-04', 29),\n",
    "(5, '2024-06-05', 26);\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d575a103-ed92-41d0-be78-690f120731cd",
   "metadata": {},
   "source": [
    "* Solution here\n",
    "``` sql\n",
    "select Id\n",
    "from\n",
    "(\n",
    "select Id,RecordDate,Temperature,lag(Temperature) over( order by Id) prev_temp\n",
    "from Weather\n",
    " )\n",
    " where Temperature > prev_temp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02472a30-7d34-4b2a-a614-bcc33050a34f",
   "metadata": {},
   "source": [
    "#### 3. Given an `Activity` table with columns `player_id` (integer), `device_id` (integer), `event_date` (date), and `games_played` (integer), where `(player_id, event_date)` is the primary key, write an SQL query to report for each player and date, the total number of games played by that player until that date.\n",
    "\n",
    "\n",
    "```sql\n",
    "CREATE TABLE Activity (\n",
    "    player_id INT,\n",
    "    device_id INT,\n",
    "    event_date DATE,\n",
    "    games_played INT,\n",
    "    PRIMARY KEY (player_id, event_date)\n",
    ");\n",
    "\n",
    "INSERT INTO Activity (player_id, device_id, event_date, games_played) VALUES\n",
    "(1, 2, '2016-03-01', 5),\n",
    "(1, 2, '2016-05-02', 6),\n",
    "(1, 3, '2017-06-25', 1),\n",
    "(3, 1, '2016-03-02', 0),\n",
    "(3, 4, '2018-07-03', 5);\n",
    "```\n",
    "\n",
    "#### Expected Output\n",
    "\n",
    "```sql\n",
    "+-----------+------------+---------------------+\n",
    "| player_id | event_date | games_played_so_far |\n",
    "+-----------+------------+---------------------+\n",
    "| 1         | 2016-03-01 | 5                   |\n",
    "| 1         | 2016-05-02 | 11                  |\n",
    "| 1         | 2017-06-25 | 12                  |\n",
    "| 3         | 2016-03-02 | 0                   |\n",
    "| 3         | 2018-07-03 | 5                   |\n",
    "+-----------+------------+---------------------+\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb76a4-8333-4e67-a3df-a1f73e12477f",
   "metadata": {},
   "source": [
    "* Solution here\n",
    "``` sql\n",
    "select player_id,event_date,sum(games_played) over(partition by player_id order by event_date) running_sum\n",
    "from activity\n",
    "order by player_id,event_date\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142e8a1f-93d8-478d-96a0-3fcbd26be90a",
   "metadata": {},
   "source": [
    "#### What is a dimension in terms of ML?\n",
    "\n",
    "\n",
    "In the context of NLP, the concept of \"dimension\" can be understood through an analogy involving boxes. Imagine we have two boxes. As humans, we can use our senses to differentiate between them by seeing, weighing, and feeling the boxes. However, a machine requires numerical inputs to understand and differentiate objects.\n",
    "\n",
    "Consider box 1 with dimensions (length, breadth, height) as (40, 30, 5) and box 2 with the same dimensions (40, 30, 5). For a machine learning model, these measurements are plotted on three axes (x, y, z), and both boxes will occupy the same point in this three-dimensional space. By measuring the distance between these points, the model will conclude that the boxes are identical.\n",
    "\n",
    "Now, if we color box 1 black and box 2 white, humans can immediately perceive the difference. To enable a machine to differentiate based on color, we introduce another dimension, say 'c' for color. Suppose we assign numerical values to colors: 1 for black and -1 for white. Now, box 1 is represented as (40, 30, 5, 1) and box 2 as (40, 30, 5, -1). When plotted in this four-dimensional space, the points representing the boxes will no longer coincide. By measuring the distance between these points, the machine learning model can determine that the boxes are different based on the added dimension of color."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bd242e-13d8-4a07-a6b3-7e6b46e01d5d",
   "metadata": {},
   "source": [
    "### Interms of Text fields\n",
    "\n",
    "---\n",
    "\n",
    "Let's imagine you have two sentences. We as humans can read and understand the sentences, identifying their meanings and differences through our cognitive abilities. However, a machine needs numerical representations to understand any text.\n",
    "\n",
    "### Step 1: Initial Representation\n",
    "\n",
    "Consider the following two sentences:\n",
    "\n",
    "- Sentence 1: \"The cat sat on the mat.\"\n",
    "- Sentence 2: \"The dog sat on the mat.\"\n",
    "\n",
    "Initially, let's represent these sentences by counting the frequency of each word. This will form a simple Bag-of-Words (BoW) representation. Assume our vocabulary is constructed from both sentences, resulting in the following list of unique words (tokens):\n",
    "\n",
    "```\n",
    "[\"the\", \"cat\", \"sat\", \"on\", \"mat\", \"dog\"]\n",
    "```\n",
    "\n",
    "We can now create a frequency vector for each sentence based on this vocabulary:\n",
    "\n",
    "For Sentence 1:\n",
    "```\n",
    "[2, 1, 1, 1, 1, 0]\n",
    "```\n",
    "For Sentence 2:\n",
    "```\n",
    "[2, 0, 1, 1, 1, 1]\n",
    "```\n",
    "\n",
    "### Step 2: Dimension Representation\n",
    "\n",
    "These vectors can be visualized as points in a six-dimensional space (since we have six unique words). The coordinates of each point correspond to the word frequencies in each sentence.\n",
    "\n",
    "### Step 3: Adding More Dimensions\n",
    "\n",
    "Now, let's extend our representation to capture more nuanced differences. Suppose we want to include information about the sentiment of the sentences. Assume we have a sentiment analysis model that assigns a sentiment score to each sentence: +1 for positive and -1 for negative.\n",
    "\n",
    "- Sentence 1 (Neutral): Sentiment score 0\n",
    "- Sentence 2 (Neutral): Sentiment score 0\n",
    "\n",
    "Now our vectors become:\n",
    "\n",
    "For Sentence 1:\n",
    "```\n",
    "[2, 1, 1, 1, 1, 0, 0]\n",
    "```\n",
    "For Sentence 2:\n",
    "```\n",
    "[2, 0, 1, 1, 1, 1, 0]\n",
    "```\n",
    "\n",
    "Next, let's add another dimension for sentence length. Assume the length of the sentence (number of words) is another feature:\n",
    "\n",
    "- Sentence 1: Length 6\n",
    "- Sentence 2: Length 6\n",
    "\n",
    "Updating our vectors:\n",
    "\n",
    "For Sentence 1:\n",
    "```\n",
    "[2, 1, 1, 1, 1, 0, 0, 6]\n",
    "```\n",
    "For Sentence 2:\n",
    "```\n",
    "[2, 0, 1, 1, 1, 1, 0, 6]\n",
    "```\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "By adding more features, we increase the dimensions in which the sentences are represented. Initially, in a lower-dimensional space (only word frequencies), the sentences might appear quite similar. However, by adding additional dimensions (sentiment score, sentence length, etc.), we can better capture the differences between them. This richer representation helps the machine learning model to understand and differentiate the sentences more effectively.\n",
    "\n",
    "---\n",
    "\n",
    "This explanation parallels your original explanation with boxes but uses text data to illustrate the concept of adding dimensions for better differentiation and understanding by a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e4ba1a-17f0-4b2b-a6fc-83d5c81a2ffd",
   "metadata": {},
   "source": [
    "## PANDAS AND NUMPY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575a45ba-c05f-48d8-92fc-cdae0d521e3a",
   "metadata": {},
   "source": [
    "#### BAG OF WORDS(BOW) is the simplest way to convert text data in to numbers(vectors) that machine can understand.\n",
    "\n",
    "* Sentence is called as document\n",
    "* every word is a token\n",
    "* set of sentences is a corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc459b-c8e0-42a8-aa56-846edcb1bdd2",
   "metadata": {},
   "source": [
    "Bag of Words (BoW) is a technique used in natural language processing (NLP) to convert text data into numerical representations for machine learning models. In BoW, a text is represented as a bag (multiset) of its words, disregarding grammar and word order but keeping multiplicity.\n",
    "\n",
    "### How BoW Works:\n",
    "1. **Tokenization:** Split the text into words (tokens).\n",
    "2. **Vocabulary Creation:** Create a list of unique words (vocabulary) from all documents.\n",
    "3. **Vectorization:** Convert each document into a vector based on the vocabulary, with each element representing the count of a specific word in that document.\n",
    "\n",
    "### Example:\n",
    "Consider the following two sentences:\n",
    "1. \"I love dogs\"\n",
    "2. \"I love cats\"\n",
    "\n",
    "#### Step-by-Step:\n",
    "1. **Tokenization:**\n",
    "   - Sentence 1: [\"I\", \"love\", \"dogs\"]\n",
    "   - Sentence 2: [\"I\", \"love\", \"cats\"]\n",
    "\n",
    "2. **Vocabulary Creation:**\n",
    "   - [\"I\", \"love\", \"dogs\", \"cats\"]\n",
    "\n",
    "3. **Vectorization:**\n",
    "   - Sentence 1: [1, 1, 1, 0] (1 \"I\", 1 \"love\", 1 \"dogs\", 0 \"cats\")\n",
    "   - Sentence 2: [1, 1, 0, 1] (1 \"I\", 1 \"love\", 0 \"dogs\", 1 \"cats\")\n",
    "\n",
    "The resulting vectors represent the text in a numerical format that can be used for further processing in machine learning models.\n",
    "\n",
    "### Summary:\n",
    "BoW converts text into a fixed-size numerical vector based on word counts, enabling machine learning algorithms to process text data. It is simple but ignores grammar and context.\n",
    "\n",
    "### Limitations of BoW:\n",
    "\n",
    "1. **Ignores Word Order:** Loses context and meaning by treating words independently.\n",
    "2. **No Semantics:** Fails to capture the meaning or relationships between words.\n",
    "3. **Sparse Representations:** Results in large, mostly empty vectors.\n",
    "4. **Lack of Generalization:** Cannot handle unseen words effectively.\n",
    "5. **Fixed Vocabulary:** Limited by the training corpus, missing new or rare words.\n",
    "\n",
    "### Why More Advanced Models are Needed:\n",
    "\n",
    "To address these issues, models like TF-IDF, Word Embeddings (Word2Vec, GloVe), and Transformer-based models (BERT, GPT) provide better context understanding, semantic representation, and efficient handling of large vocabularies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f27d5be-a4dd-46ae-8db5-c81139a1e623",
   "metadata": {},
   "source": [
    "#### BOW from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1223c936-cd2f-49b5-b665-2f9cd32acbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----This is the cleaned text--------\n",
      "                                        Sentences\n",
      "0          hello world this is a sample sentence \n",
      "1  learning python is fun practice makes perfect \n",
      "2           data science with pandas is powerful \n",
      "3  machine learning involves algorithms and data \n",
      "4  clean your data remove noise and punctuations \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----This is the vocab------\n",
      "['noise', 'learning', 'practice', 'machine', 'science', 'makes', 'and', 'powerful', 'remove', 'python', 'a', 'perfect', 'your', 'clean', 'sample', 'punctuations', 'hello', 'world', 'involves', 'with', 'fun', 'data', 'sentence', 'pandas', 'is', 'algorithms', 'this']\n",
      "\n",
      "\n",
      "\n",
      "                                        Sentences  \\\n",
      "0          hello world this is a sample sentence    \n",
      "1  learning python is fun practice makes perfect    \n",
      "2           data science with pandas is powerful    \n",
      "3  machine learning involves algorithms and data    \n",
      "4  clean your data remove noise and punctuations    \n",
      "\n",
      "                                          vector_rep  \n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, ...  \n",
      "1  [0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, ...  \n",
      "2  [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "3  [0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "4  [1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, ...  \n"
     ]
    }
   ],
   "source": [
    "# Let's create a simple BOW model without using libraries.\n",
    "## use chatgpt for hints\n",
    "# Create three diff functions\n",
    "# one for cleaning(removing punctuations, html tags non words)\n",
    "# one for creating vocab \n",
    "# last for representing sentence using vectors\n",
    "# USE aaply and LMBDA function wherevr applicable\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"Sentences\": [\n",
    "        \"HELLO world! This is a <div>sample</div> sentence.\",\n",
    "        \"Learning PYTHON is fun. <p>Practice</p> makes perfect.\",\n",
    "        \"Data Science with <a href='#'>pandas</a> is powerful!\",\n",
    "        \"Machine learning involves <span>algorithms</span> and data.\",\n",
    "        \"Clean your DATA: Remove <b>noise</b> and punctuations.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Creating the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def cleaning_lower(string):\n",
    "    string = re.sub(r'<.*?>',' ',string)\n",
    "    string = re.sub(r'[^A-Za-z]',' ',string)\n",
    "    string = re.sub(r'\\s+',' ',string)\n",
    "    string = string.lower()\n",
    "    return string\n",
    "\n",
    "df['Sentences'] = df['Sentences'].apply(lambda x : cleaning_lower(x))\n",
    "print('-----This is the cleaned text--------')\n",
    "print(df)\n",
    "print('\\n\\n\\n')\n",
    "\n",
    "\n",
    "def create_vocab(df,column_name):\n",
    "     tokens_list = df[column_name].apply(lambda x: x.split())\n",
    "     all_tokens = tokens_list.sum()  # Flatten the list of lists\n",
    "     vocab = list(set(all_tokens))  # Get unique words\n",
    "     return vocab\n",
    "\n",
    "vocab = create_vocab(df,'Sentences')\n",
    "\n",
    "print('----This is the vocab------')\n",
    "print(vocab)\n",
    "print('\\n\\n')\n",
    "\n",
    "def create_vector(sentence,vocab):\n",
    "    bow = [0]*len(vocab)\n",
    "    for word in sentence.split():\n",
    "        if word in vocab:\n",
    "            index = vocab.index(word)\n",
    "            bow[index] += 1\n",
    "    return bow\n",
    "\n",
    "\n",
    "\n",
    "df['vector_rep'] = df['Sentences'].apply(lambda x: create_vector(x,vocab))\n",
    "print(df)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0dc11-7aa5-4a82-a9d9-d1ee0092bb00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
